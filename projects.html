<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>All Projects | Manas Reddy Arumalla</title>
  
  <!-- Styles -->
  <link rel="stylesheet" href="style.css" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
</head>
<body>

  <!-- ================= NAVBAR ================= -->
  <nav class="pill-nav">
    <div class="nav-container">
      <div class="nav-name">Manas Reddy Arumalla</div>
      <ul>
        <li><a href="index.html#home">Home</a></li>
        <li><a href="index.html#about">About</a></li>
        <li><a href="index.html#skills">Skills</a></li>
        <li><a href="index.html#experience">Experience</a></li>
        <li><a href="index.html#certifications">Certifications</a></li>
        <li><a href="index.html#contact">Contact</a></li>
      </ul>
    </div>
  </nav>

  <!-- ================= PROJECTS SHOWCASE ================= -->
  <section class="section projects-section">
    <h2 class="section-title">All <span class="highlight">Projects</span></h2>
    <p class="section-subtitle">
      A collection of my robotics and engineering projects, blending innovation, problem-solving, and technical skills.
    </p>

    <div class="projects-grid">
      <!-- Project Cards -->
      <div class="project-card" data-project="pharmabot">
        <img src="assets/Pharma.png" alt="PharmaBot" />
        <div class="project-info">
          <h3>PharmaBot – Autonomous Medicine Delivery</h3>
          <p>PharmaBot autonomously delivers medicines using Dijkstra-based path planning, image processing with OpenCV, and a Raspberry Pi for control.</p>
          <p class="tags">Raspberry Pi, CoppeliaSim, OpenCV, Python, Socket Communication</p>
        </div>
      </div>

      <div class="project-card" data-project="sony">
        <img src="assets/Sony.jpg" alt="Sony SSUP" />
        <div class="project-info">
          <h3>Sony SSUP Project</h3>
          <p>Designed a versatile robot with omni-directional mobility and morphing capabilities, enabling it to adapt to various terrains and tasks efficiently.</p>
          <p class="tags">Sony Spressence, Arduino, Machining, Designing, Controls</p>
        </div>
      </div>

      <div class="project-card" data-project="inverted-pendulum">
        <img src="assets\Invpend.png" alt="Inverted Pendulum" />
        <div class="project-info">
          <h3>Control Strategies for Two-Wheeled Inverted Pendulum</h3>
          <p>Derived the dynamics of a two-wheeled inverted pendulum and implemented multiple control strategies in MATLAB, followed by testing in MuJoCo.</p>
          <p class="tags">MATLAB, MuJoCo, Control Systems, Robot Dynamics</p>
        </div>
      </div>

      <div class="project-card" data-project="quadcopter">
        <img src="assets\dronesim.jpg" alt="Quadcopter Control" />
        <div class="project-info">
          <h3>Quadcopter Control</h3>
          <p>Developed a quadcopter simulation implementing advanced control strategies including PID, LQR, Backstepping, and MPC.</p>
          <p class="tags">MATLAB, Control System, Drone Dynamics</p>
        </div>
      </div>

      <div class="project-card" data-project="self-balancing">
        <img src="assets/self.jpg" alt="Self-Balancing Bot" />
        <div class="project-info">
          <h3>Self-Balancing Bot</h3>
          <p>Designed a self-balancing robot inspired by inverted pendulum dynamics, utilizing PID and LQR control systems.</p>
          <p class="tags">Arduino, PID, LQR, Control Systems, MATLAB</p>
        </div>
      </div>

      <div class="project-card" data-project="river">
        <img src="assets/rivercleaning.png" alt="River Cleaning Robot" />
        <div class="project-info">
          <h3>River Cleaning Robot</h3>
          <p>Simulated a river-cleaning robot designed to collect floating waste using an object detection model.</p>
          <p class="tags">PX4, ROS2, Jetson Orin Nano, Gazebo, CAD, Navigation</p>
        </div>
      </div>

      <div class="project-card" data-project="hand">
        <img src="assets\handtrackmodel.png" alt="Hand Tracking" />
        <div class="project-info">
          <h3>Robotic Wrist Control Using Hand Tracking</h3>
          <p>Built a real-time hand tracking system with OpenCV, replicating human hand motions on a robotic wrist in MuJoCo simulation.</p>
          <p class="tags">MuJoCo, Python, OpenCV, Control System</p>
        </div>
      </div>

      <div class="project-card" data-project="drone">
        <img src="assets/Drone.png" alt="Racing Drone" />
        <div class="project-info">
          <h3>Racing Drone</h3>
          <p>Assembled and fine-tuned a fully functional racing drone, gaining expertise in component selection, calibration, and high-speed flight dynamics.</p>
          <p class="tags">Flight Controller, BetaFlight, Drone Components</p>
        </div>
      </div>

      <div class="project-card" data-project="robo-soccer">
        <img src="assets/robosoccer.png" alt="Robo Soccer" />
        <div class="project-info">
          <h3>Opto-Electric Robo Soccer</h3>
          <p>Developed for the Robotics Club at Amrita Vishwa Vidyapeetham, this soccer-playing robot operated autonomously using light-based signaling.</p>
          <p class="tags">Arduino, 3D Printing, LDR Sensors, Actuators</p>
        </div>
      </div>

      <div class="project-card" data-project="chair">
        <img src="assets\ARVR.jpg" alt="AR/VR Chair" />
        <div class="project-info">
          <h3>AR/VR Motion Simulator Chair</h3>
          <p>Designed and developed a VR motion simulator chair, focusing on enhancing immersion through design optimization and motion synchronization.</p>
          <p class="tags">Fusion 360, CAD, Simulation</p>
        </div>
      </div>
    </div>

    <!-- Back to Home -->
    <div class="explore-projects">
      <a href="index.html#projects" class="explore-btn">
        </i> Back to Portfolio
      </a>
    </div>
  </section>


  <!-- ================= PROJECT MODALS ================= -->
  <section id="project-modals">

<!-- PharmaBot -->
    <div id="pharmabot" class="modal">
      <div class="modal-content">
        <span class="close">&times;</span>
        <h2>PharmaBot Project – E-Yantra, IIT Bombay</h2>
        <div class="modal-gallery">
          <img src="assets/Pharmabot.png" alt="PharmaBot" />
          <div class="video-container">
            <iframe src="https://www.youtube.com/embed/Rl8GzILtZo4?autoplay=1&loop=1&mute=1&playlist=Rl8GzILtZo4" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div>
          <div class="video-container">
            <iframe src="https://www.youtube.com/embed/wk6wSKj-q1c?autoplay=1&loop=1&mute=1&playlist=wk6wSKj-q1c" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div>
        </div>
        <p>
          The <strong>PharmaBot</strong> project was developed as part of the <em>E-Yantra Robotics Competition</em> organized by <strong>IIT Bombay</strong>. 
          The objective was to design a robot capable of autonomously delivering medicines from a pharmacy to designated houses using efficient path planning and intelligent control.
        </p>
        <!-- Key Features -->
        <h3 style="color:#58a6ff;">Key Features</h3>
        <ul>
        <li>
            <strong>Path Planning with Dijkstra Algorithm:</strong>  
            Implemented Dijkstra’s algorithm to compute the shortest and most efficient routes 
            on a grid-based map, ensuring optimal navigation while avoiding detours and obstacles.
        </li>
        <li>
            <strong>Image Processing with OpenCV:</strong>  
            Used computer vision techniques for detecting road markers and obstacles.  
            A camera integrated with OpenCV enabled real-time decision-making for smooth navigation.
        </li>
        <li>
            <strong>Control via Raspberry Pi:</strong>  
            Raspberry Pi served as the central controller, managing sensors, motors, and the camera 
            while executing algorithms for decision-making and navigation.
        </li>
        <li>
            <strong>Simulation in CoppeliaSim:</strong>  
            Simulated the robot’s behavior and navigation strategies in CoppeliaSim before deployment, 
            enabling safe testing across multiple scenarios.
        </li>
        </ul>
        <br>
        <!-- Skills -->
        <h3 style="color:#58a6ff;">Skills Gained</h3>
        <ul>
        <li>Python programming for robotics applications</li>
        <li>Raspberry Pi hardware control</li>
        <li>Computer vision and image processing with OpenCV</li>
        <li>Simulation and testing using CoppeliaSim</li>
        <li>Autonomous navigation and control system design</li>
        </ul>
        <br>
        <!-- Team -->
        <p>
        Developed in collaboration with:
        Vybhav Raghavendra Devarakonda, M. Vignesh, and K. Gnanesh.
        </p>
        <!-- Git Link-->
        <div class="project-links">
          <a href="https://github.com/Manas-arumalla/eyrc22_Pharma_Bot.git" target="_blank" class="github-btn">
            <button style="font-size:40px">GitHub <i class="fa fa-github"></i></button>
          </a>
        </div>
      </div>
    </div>

<!-- Sony SSUP -->
    <div id="sony" class="modal">
      <div class="modal-content">
        <span class="close">&times;</span>
        <h2>Sony SSUP:COWKIN: Smart Cow Health Monitoring System</h2>
        <div class="modal-gallery">
          <img src="assets/Sony.jpg" alt="Sony Project" />
        </div>
        <p>
          As part of the Sony Spresense University Program (SSUP), this project encompassed two innovative developments: a Smart Livestock Monitoring System and an Omni Directional Multi-Morphing Robot. The Smart Livestock Monitoring System utilized the Sony Spresense board to track vital parameters such as body temperature, activity levels, and geolocation of cows. This IoT-enabled solution provided real-time health monitoring, enabling farmers to detect issues early and optimize livestock management for better animal welfare and operational efficiency. The Multi-Morphing Robot showcased advanced robotics with shape-shifting capabilities, omni-directional movement, and animal-like leg joints for enhanced adaptability. It was equipped with image processing and recognition capabilities, allowing it to interact intelligently with its environment. The robot’s versatility highlighted potential applications in dynamic and challenging terrains.Both developments leveraged the Sony Spresense board's low-power, high-performance architecture, demonstrating its utility in IoT and robotics. This project exemplified how innovation and technology can address diverse challenges in agriculture and robotics.
        </p>
      </div>
    </div>

<!-- Inverted Pendulum -->
    <div id="inverted-pendulum" class="modal">
      <div class="modal-content">
        <span class="close">&times;</span>
        <h2>Control Strategies for Two-Wheeled Inverted Pendulum</h2>
        <!-- Gallery -->
        <div class="modal-gallery">
        <img src="assets\Poleplacement.png" alt="Two-Wheeled Inverted Pendulum plots">
        <img src="assets\Poleplacementmujoco.png" alt="MuJoCo plots">
        <video autoplay loop muted playsinline controls>
            <source src="assets\Invertedpend.mp4" type="video/mp4">
            Your browser does not support the video tag.
        </video>
        </div>
        <!-- Overview -->
        <p>
        This project focused on deriving the <strong>dynamics of a two-wheeled inverted pendulum</strong> 
        and applying advanced control techniques to stabilize and maneuver the inherently unstable system.  
        The dynamics were modeled in <strong>MATLAB</strong> and tested in <strong>MuJoCo</strong> 
        for real-world performance evaluation, with controller gains optimized using 
        <strong>Genetic Algorithms (GA)</strong> for robustness.
        </p>
        <!-- Control Techniques -->
        <h3 style="color:#58a6ff;">Control Techniques Implemented</h3>
        <ul>
        <li><strong>LQR (Linear Quadratic Regulator):</strong> Designed for optimal trade-off between control effort and stability.</li>
        <li><strong>Pole Placement:</strong> Achieved specific dynamic responses by placing system poles at desired locations.</li>
        <li><strong>MPC (Model Predictive Control):</strong> Enabled predictive stabilization under trajectory tracking constraints.</li>
        <li><strong>H∞ Control:</strong> Improved robustness against disturbances and model uncertainties.</li>
        <li><strong>Carleman Linearization + LQR:</strong> Applied Carleman linearization to handle nonlinear dynamics, then stabilized using LQR.</li>
        <li><strong>Sliding Mode Control (SMC):</strong> Ensured robustness and strong rejection of external disturbances.</li>
        <li><strong>LPV (Linear Parameter-Varying Control):</strong> Adapted to system changes by parameterizing dynamics.</li>
        <li><strong>LQR + L1 Adaptive:</strong> Combined optimal control with adaptive compensation for unknown dynamics.</li>
        <li><strong>LQR + SMC + Backstepping:</strong> Hybrid approach for enhanced robustness and nonlinear control.</li>
        <li><strong>EPSAC (Extended Predictive Self-Adaptive Control):</strong> Provided adaptive predictive control for varying conditions.</li>
        <li><strong>NDI + SMC (Nonlinear Dynamic Inversion + SMC):</strong> Used nonlinear inversion for precise control, with SMC for disturbance rejection.</li>
        </ul>
        <br>
        <!-- Outcomes -->
        <h3 style="color:#58a6ff;">Outcomes & Applications</h3>
        <p>
        This project highlighted the comparative performance of <strong>classical, modern, and 
        hybrid control strategies</strong> on an unstable system.  
        The insights gained are directly applicable to <strong>self-balancing robots, humanoids, 
        drones, and autonomous vehicles</strong>, where robust and adaptive control 
        is critical for stability in uncertain environments.
        </p>
        <!-- Git Link-->
        <div class="project-links">
          <a href="https://github.com/Manas-arumalla/Control-strategies-for-two-wheeled-inverted-pendulum.git" target="_blank" class="github-btn">
            <button style="font-size:40px">GitHub <i class="fa fa-github"></i></button>
          </a>
        </div>
    </div>
    </div>

<!-- Quadcopter -->
    <div id="quadcopter" class="modal">
      <div class="modal-content">
        <span class="close">&times;</span>
        <h2>Quadcopter Control – Simulation</h2>
        <!-- Gallery -->
        <div class="modal-gallery">
        <img src="assets\dronesim.jpg" alt="Quadcopter Simulation Screenshot">
        <img src="assets\dronesimplot.png" alt="Trajectory Following">
        <video autoplay loop muted playsinline controls>
            <source src="assets\quadcoptercontrol.mp4" type="video/mp4">
            Your browser does not support the video tag.
        </video>
        </div>
        <!-- Overview -->
        <p>
        This project focused on simulating a <strong>quadcopter control system</strong> capable 
        of accurately following predefined trajectories such as waypoints, straight-line paths, 
        circular loops, and even complex curves like a helix.  
        The goal was to analyze and compare different <strong>control strategies</strong> for 
        stability, precision, and performance.
        </p>
        <!-- Project Highlights -->
        <h3 style="color:#58a6ff;">Project Highlights</h3>
        <ul>
        <li>
            <strong>Trajectory Tracking:</strong>  
            Implemented controllers that enabled the quadcopter to follow <strong>waypoints</strong> 
            and continuous trajectories with minimal deviation.
        </li>
        <li>
            <strong>Advanced Control Techniques:</strong>  
            Designed and tested multiple strategies including <strong>PID, LQR, Backstepping, 
            and Model Predictive Control (MPC)</strong>, comparing their effectiveness 
            in trajectory tracking.
        </li>
        <li>
            <strong>Genetic Algorithm (GA) Optimization:</strong>  
            Used GA to automatically tune controller gains, ensuring optimal performance 
            under varying conditions.
        </li>
        <li>
            <strong>Simulation Outputs:</strong>  
            Analyzed <strong>X, Y, and Z position errors</strong> during trajectory tracking, 
            as well as <strong>rotor thrust profiles</strong>, to evaluate the control 
            system’s efficiency and stability.
        </li>
        </ul>
        <br>
        <!-- Outcomes -->
        <h3 style="color:#58a6ff;">Outcomes & Applications</h3>
        <p>
        This project provided a deeper understanding of how <strong>different control methods</strong> 
        affect quadcopter dynamics in trajectory tracking.  
        The approaches explored here have direct applications in <strong>autonomous drones, 
        delivery systems, aerial robotics research, and swarm drone coordination</strong>.
        <!-- Git Link-->
        <div class="project-links">
          <a href="https://github.com/Manas-arumalla/Quadcopter_Control_Simulation.git" target="_blank" class="github-btn">
            <button style="font-size:40px">GitHub <i class="fa fa-github"></i></button>
          </a>
        </div>
      </div>
    </div>


<!-- Self-Balancing -->
    <div id="self-balancing" class="modal">
      <div class="modal-content">
        <span class="close">&times;</span>
        <h2>Self-Balancing Robot</h2>
        <!-- Gallery -->
        <div class="modal-gallery">
            <img src="assets\self.jpg" alt="Self-Balancing Robot">
            <img src="assets\selfbotside.jpg" alt="Self-Balancing Robot">
            <video autoplay loop muted playsinline controls>
            <source src="assets\selfbalancingbot.mp4" type="video/mp4">
            Your browser does not support the video tag.
            </video>
        </div>
        <!-- Overview -->
        <p>
            This project focused on designing and building a <strong>self-balancing robot</strong> 
            inspired by the physics of the inverted pendulum. The system was engineered to 
            maintain balance and stability even on uneven terrains, leveraging advanced control strategies 
            for real-time adjustments and smooth navigation.
        </p>
        <!-- Project Highlights -->
        <h3 style="color:#58a6ff;">Project Highlights</h3>
        <ul>
            <li>
            <strong>Control Strategies:</strong>  
            Implemented <strong>PID (Proportional-Integral-Derivative)</strong> and 
            <strong>LQR (Linear Quadratic Regulator)</strong> controllers to stabilize 
            the robot under different disturbance conditions.
            </li>
            <li>
            <strong>Hardware Integration:</strong>  
            Used an <strong>Arduino microcontroller</strong> with IMU sensors for real-time 
            feedback, ensuring precise angle and position detection.
            </li>
            <li>
            <strong>MATLAB Simulation:</strong>  
            Designed and simulated the robot’s control dynamics in MATLAB to fine-tune 
            system parameters before physical implementation.
            </li>
            <li>
            <strong>Terrain Adaptability:</strong>  
            Optimized the design to maintain stability on uneven surfaces, demonstrating 
            the effectiveness of combining multiple control systems.
            </li>
        </ul>
        <br>
        <!-- Outcomes -->
        <h3 style="color:#58a6ff;">Outcomes & Applications</h3>
        <p>
            The project demonstrated how <strong>classical and modern control techniques</strong> 
            can be applied to real-world robotics. Beyond academic learning, the principles 
            from this robot are directly applicable to <strong>self-balancing vehicles, 
            humanoid robots, and mobile robotic platforms</strong> requiring dynamic stability.
        </p>
        <!-- Team -->
        <p>
            <em>Completed under the mentorship of:</em>  
            <strong>Dr. Rammohan Sriramdas</strong>, Amrita Vishwa Vidyapeetham  
            <br>
            <em>In collaboration with teammate:</em>  
            <strong>Vybhav Raghavendra Devarakonda</strong>.
        </p>
        <!-- Git Link-->
        <div class="project-links">
          <a href="https://github.com/Manas-arumalla/Steady-Stride_Self-balancing-robot.git" target="_blank" class="github-btn">
            <button style="font-size:40px">GitHub <i class="fa fa-github"></i></button>
          </a>
        </div>
      </div>
    </div>

<!-- River Cleaning -->
    <div id="river" class="modal">
      <div class="modal-content">
        <span class="close">&times;</span>
        <h2>River Cleaning Robot – Anvi Robotics</h2>
        <!-- Gallery -->
        <div class="modal-gallery">
            <img src="assets/rivercleaning.png" alt="River Cleaning Robot">
        </div>
        <!-- Overview -->
        <p>
            As part of a project with <strong>Anvi Robotics</strong>, I contributed to the 
            design and simulation of a <strong>river-cleaning robot</strong> aimed at addressing 
            the problem of water pollution. The primary goal was to create a robotic system capable 
            of autonomously detecting and collecting floating waste from water bodies.
        </p>
        <!-- Project Highlights -->
        <h3 style="color:#58a6ff;">Project Highlights</h3>
        <ul>
            <li>
            <strong>ROS2 & Gazebo Simulation:</strong>  
            Implemented ROS2 for robot control and Gazebo for simulating navigation and 
            waste-collection mechanisms in a realistic water environment.
            </li>
            <li>
            <strong>AI-Powered Object Detection:</strong>  
            Integrated an object detection model to identify floating waste, enabling precise 
            trash detection and collection while avoiding false positives.
            </li>
            <li>
            <strong>PX4 & ROS2 Integration:</strong>  
            Established seamless communication between hardware and software systems 
            using PX4 flight control integrated with ROS2 for efficient control and navigation.
            </li>
            <li>
            <strong>Component Selection & Procurement:</strong>  
            Gained hands-on experience in selecting suitable components within 
            technical and budgetary constraints, ensuring compatibility and performance.
            </li>
        </ul>
        <br>
        <!-- Impact -->
        <h3 style="color:#58a6ff;">Impact & Learning</h3>
        <p>
            This project demonstrated the potential of robotics in <strong>environmental sustainability</strong> 
            by showcasing how automation can tackle real-world ecological challenges.  
            It enhanced my knowledge of <strong>robotic simulation, system integration, and 
            advanced technologies like ROS2 and PX4</strong>.
        </p>
        <!-- Team -->
        <p>
            <em>Completed under the mentorship of:</em>  
            Mr. Pranav Korra and Mr. Naveen, as part of <strong>Anvi Robotics</strong> (led by Mr. Kisshhan PSV),  
            in collaboration with my teammate <strong>Vybhav Raghavendra Devarakonda</strong>.
        </p>
      </div>
    </div>

<!-- Hand Tracking -->
    <div id="hand" class="modal">
      <div class="modal-content">
        <span class="close">&times;</span>
        <h2>Robotic Wrist Control Using Hand Tracking</h2>
        <!-- Gallery -->
        <div class="modal-gallery">
            <img src="assets\handtrack.png" alt="Hand Tracking with OpenCV">
            <img src="assets\handtrackmodel.png" alt="Robotic Wrist Simulation">
            <video autoplay loop muted playsinline controls>
            <source src="assets\Handtrackrun.mp4" type="video/mp4">
            Your browser does not support the video tag.
            </video>
        </div>
        <!-- Overview -->
        <p>
            This project integrated <strong>computer vision</strong> with <strong>robotics simulation</strong> 
            to enable real-time control of a robotic wrist. Using OpenCV, hand movements were tracked through 
            a live camera feed and translated into control commands, which were then executed in a 
            <strong>MuJoCo simulation</strong>, allowing the robotic wrist to replicate human gestures with high precision.
        </p>
        <!-- Project Highlights -->
        <h3 style="color:#58a6ff;">Project Highlights</h3>
        <ul>
            <li>
            <strong>Real-Time Hand Tracking:</strong>  
            Implemented computer vision algorithms in <strong>OpenCV</strong> to detect and track 
            hand keypoints with accuracy and low latency.
            </li>
            <li>
            <strong>Human-to-Robot Motion Mapping:</strong>  
            Developed a mechanism to map human hand movements into control signals 
            for a <strong>robotic wrist model</strong> in simulation.
            </li>
            <li>
            <strong>MuJoCo Simulation:</strong>  
            Tested the robotic wrist in <strong>MuJoCo</strong>, ensuring smooth replication 
            of motions and validating system dynamics.
            </li>
            <li>
            <strong>Control System Integration:</strong>  
            Designed a control loop that allowed the robotic wrist to follow human inputs 
            in real time, bridging <strong>vision-based sensing with robotic actuation</strong>.
            </li>
        </ul>
        <!-- Outcomes -->
        <h3 style="color:#58a6ff;">Outcomes & Applications</h3>
        <p>
            The project demonstrated the potential of combining <strong>computer vision, control systems, 
            and physics-based simulation</strong> for intuitive human–robot interaction.  
            Such systems can be applied in <strong>teleoperation, rehabilitation robotics, 
            assistive devices, and human-in-the-loop control frameworks</strong>.
        </p>
        <!-- Git Link-->
        <div class="project-links">
          <a href="https://github.com/Manas-arumalla/Hand-Tracking-Control.git" target="_blank" class="github-btn">
            <button style="font-size:40px">GitHub <i class="fa fa-github"></i></button>
          </a>
        </div>
      </div>
    </div>

<!-- Racing Drone -->
    <div id="drone" class="modal">
      <div class="modal-content">
        <span class="close">&times;</span>
        <h2>Racing Drone</h2>
        <!-- Gallery -->
        <div class="modal-gallery">
        <img src="assets\Drone.png" alt="Racing Drone Build">
        </div>
        <!-- Overview -->
        <p>
        This project involved <strong>assembling and fine-tuning a high-performance racing drone</strong>, 
        providing hands-on experience in UAV hardware integration, flight calibration, 
        and performance optimization.  
        The build emphasized component selection, system reliability, and agility during 
        high-speed flight.
        </p>
        <!-- Project Highlights -->
        <h3 style="color:#58a6ff;">Project Highlights</h3>
        <ul>
        <li>
            <strong>Component Selection & Assembly:</strong>  
            Selected and integrated motors, ESCs, propellers, flight controller, and frame 
            to build a stable, lightweight racing drone.
        </li>
        <li>
            <strong>Flight Controller Configuration:</strong>  
            Configured and tuned the drone using <strong>Betaflight</strong>, optimizing 
            PID settings for agility and precision.
        </li>
        <li>
            <strong>Calibration & Testing:</strong>  
            Performed IMU calibration, ESC synchronization, and thrust tests to ensure 
            smooth flight dynamics and safety.
        </li>
        <li>
            <strong>High-Speed Flight:</strong>  
            Conducted trial flights to validate stability and responsiveness under racing 
            conditions, analyzing performance during sharp turns and accelerations.
        </li>
        </ul>
        <!-- Outcomes -->
        <h3 style="color:#58a6ff;">Outcomes & Applications</h3>
        <p>
        The project strengthened my expertise in <strong>drone assembly, control tuning, 
        and flight dynamics</strong>.  
        The skills gained are applicable to <strong>UAV prototyping, aerial robotics research, 
        FPV drone racing, and autonomous drone development</strong>.
        </p>
      </div>
    </div>

<!-- Robo Soccer -->
    <div id="robo-soccer" class="modal">
      <div class="modal-content">
        <span class="close">&times;</span>
        <h2>Opto-Electric Robo Soccer</h2>
        <!-- Gallery -->
        <div class="modal-gallery">
            <video autoplay loop muted playsinline controls>
            <source src="assets\robosoccer.mp4" type="video/mp4">
            Your browser does not support the video tag.
            </video>
        </div>
        <!-- Overview -->
        <p>
            Developed as part of the <strong>Robotics Club at Amrita Vishwa Vidyapeetham</strong>, 
            this project involved designing and building an <strong>autonomous soccer-playing robot</strong> 
            guided by light signals. The robot used <strong>LDR (Light Dependent Resistor) sensors</strong> 
            to detect illumination patterns and translate them into movement commands, enabling 
            reactive play on the soccer field.
        </p>
        <!-- Project Highlights -->
        <h3 style="color:#58a6ff;">Project Highlights</h3>
        <ul>
            <li>
            <strong>Sensor-Based Control:</strong>  
            Implemented <strong>LDR sensors</strong> to detect light intensity and guide 
            robot actions based on optical input.
            </li>
            <li>
            <strong>Arduino Integration:</strong>  
            Programmed an <strong>Arduino microcontroller</strong> to process sensor data 
            and control motors for autonomous movement.
            </li>
            <li>
            <strong>Custom Design:</strong>  
            Designed and fabricated the robot chassis using <strong>3D printing</strong>, 
            integrating sensors, actuators, and circuitry.
            </li>
            <li>
            <strong>Autonomous Soccer Play:</strong>  
            The robot responded to light cues as “game signals,” demonstrating 
            coordinated movement and interactive gameplay.
            </li>
        </ul>
        <br>
        <!-- Outcomes -->
        <h3 style="color:#58a6ff;">Outcomes & Applications</h3>
        <p>
            This project enhanced my understanding of <strong>light-based sensing, actuator control, 
            and robotics system integration</strong>.  
            Beyond being an engaging robotics challenge, the principles learned are relevant 
            to <strong>autonomous vehicles, industrial automation, and sensor-driven robotics systems</strong>.
        </p>
      </div>
    </div>

<!-- AR/VR Chair -->
    <div id="chair" class="modal">
      <div class="modal-content">
        <span class="close">&times;</span>
        <h2>AR/VR Motion Simulator Chair</h2>
        <!-- Gallery -->
        <div class="modal-gallery">
            <img src="assets\ARVR.jpg" alt="Fusion 360 CAD Model">
        </div>
        <!-- Overview -->
        <p>
            This project involved the <strong>design and development of an AR/VR motion simulator chair</strong> 
            aimed at enhancing user immersion through precise motion synchronization with virtual environments.  
            Using <strong>Fusion 360</strong>, the chair’s mechanical design was modeled, refined, and simulated 
            to ensure accurate responsiveness, stability, and comfort during operation.
        </p>
        <!-- Project Highlights -->
        <h3 style="color:#58a6ff;">Project Highlights</h3>
        <ul>
            <li>
            <strong>Mechanical Design:</strong>  
            Designed the chair in <strong>Fusion 360</strong>, focusing on ergonomics, motion range, 
            and load distribution.
            </li>
            <li>
            <strong>Iterative Prototyping:</strong>  
            Applied an iterative design process to identify performance gaps, improving stability 
            and responsiveness.
            </li>
            <li>
            <strong>Motion Synchronization:</strong>  
            Simulated motion profiles to achieve <strong>realistic dynamic feedback</strong> 
            aligned with VR environments.
            </li>
        </ul>
        <br>
        <!-- Outcomes -->
        <h3 style="color:#58a6ff;">Outcomes & Applications</h3>
        <p>
            The project demonstrated the potential of combining <strong>mechanical design, simulation, 
            and immersive technology</strong> to enhance user interaction.  
            Applications include <strong>VR training simulators, gaming platforms, automotive and 
            aerospace training systems, and rehabilitation technologies</strong>.
        </p>
      </div>
    </div>

</section>

  <!-- ================= FOOTER ================= -->
  <footer class="footer">
    <div class="footer-container">
      <div class="footer-message">
        <h2>Contact Me</h2>
        <p>
          Let’s collaborate and innovate together. <br />
          Open to connecting with passionate learners, researchers, and professionals in robotics and automation.
        </p>
      </div>
      <div class="footer-info">
        <h3>Info</h3>
        <p><strong>Manas Reddy Arumalla</strong></p>
        <p>
          Miyapur,<br />
          Hyderabad,<br />
          Telangana - 500049,<br />
          India
        </p>
        <p>Email: <a href="mailto:manasreddyarumalla@gmail.com">manasreddyarumalla@gmail.com</a></p>
        <p>Phone: <a href="tel:+919700171171">+91 9700171171</a></p>
      </div>
    </div>
    <p class="footer-copy">© 2025 Manas Reddy Arumalla. All Rights Reserved.</p>
  </footer>

  <!-- ================= SCRIPTS ================= -->
  <script src="script.js"></script>
</body>
</html>
